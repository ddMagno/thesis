\chapter[Optimisation]{Optimisation et généricité}
\label{chap:roboptim}

\epigraph{Text text text text text text text text text text text text
  text text text text text text text text text text text text text
  text text text text text text text text text text text text text
  text text text text text text text text text text text text text
  text text text text}{Some Author}
\clearpage

\section[Optimisation]{Optimisation numérique et robotique}

\subsection{Introduction à l'optimisation numérique}

La robotique s'appuie sur différents outils mathématiques pour
résoudre les problèmes auxquels elle se trouve confrontée. Parmi ces
outils, l'optimisation numérique figure à une place de choix.


L'optimisation numérique est une branche des mathématiques permettant
de choisir automatiquement la meilleure solution parmi un ensemble de
solutions possibles. Les applications possibles couvrent des domaines
variés de la recherche opérationnelle aux statistiques et bien sûr la
robotique. Dans ce domaine particulier, l'optimisation numérique
permets par exemple d'optimiser un mouvement pour en améliorer
certains caractéristiques ou bien encore trouver la prochaine commande
à envoyer aux moteurs du robot afin de réaliser une tâche donnée.



Résoudre un problème d'optimisation numérique signifie trouver les
meilleurs paramètres solutionnant le problème. Par meilleurs, il faut
entendre les paramètres minimisant la valeur d'une fonction de
coût. Intuitivement, on peut se représenter cette fonction comme un
indicateur de la ``qualité'' de la solution trouvée. Une solution
présentant un coût fort sera donc peu satisfaisante tandis qu'une
solution présentant un coût faible sera, elle, très attrayante. Tout
le raisonement est ensuite fondé sur la linéarité -- au moins locale!
-- de cette fonction de coût. Plus simplement, près d'une mauvaise
solution, il n'y aura que des solutions légèrement meilleures et
légèrement pires, mais jamais trop différentes. De ce fait, il
``suffit'' de chercher dans quelle direction aller pour se diriger
vers les meilleurs solutions pour finir par les trouver. Cette
approche implique une limitation majeure: si la fonction de coût n'est
pas convexe, on ne trouvera pas forcément la meilleure solution
globale -- parmi toutes les solutions -- mais ma meilleure solution
locale. C'est à dire qu'au voisinage de cette solution, toutes les
autres solutions sont de moins bonnes qualités. Dans cette situation,
tous les solveurs arrêtent leur recherche, mais rien ne garantit
qu'ailleurs il n'existe pas une autre solution de meilleure qualité.


Ce raisonnement permets de trouver les meilleurs paramètres pour un
problème donné, mais il est rare qu'une fonction de coût seule puisse
capturer complètement un problème donné. En fonctionnant de manière
indépendante du problème sous-jacent, on confère aux solveurs une
grande polyvalence. Mais par là même, il devient nécessaire
d'expliciter sous quelles conditions une solution au problème donné
est acceptable. Prenons un exemple: pour aller d'un point $A$ à un
point $B$ le plus rapidement possible, se déplacer avec une vitesse
infinie est sans aucun doute la solution optimale. Cependant, une
telle réponse ne présente guère d'intérêt dans la mesure où aucun
système physique ne sera en mesure de l'executer.


Deux stratégies peuvent alors être choisies. La première est
d'exprimer directement dans la fonction de coût cette information
supplémentaire. Dans le cadre de l'exemple précédemment cité, on
pourrait concevoir une fonction de coût réalisant la somme du temps de
déplacement et de la vitesse moyenne du robot. De ce fait, une vitesse
trop grande pénalise le résultat et par ce biais, le solveur tentera
plutôt de transformer la trajectoire géométrique plutôt que de jouer
sur la vitesse de déplacement du système. La limite de cette approche
est simple à comprendre: au fur et à mesure que les biais s'accumulent
-- le plus souvent en sommant les uns aux autres --, le coût initial
peut se retrouver ignoré par le solveur car numériquement
négligeable. La fonction de coût n'a alors plus aucune justification
physique et ses variations peuvent devenir de plus en plus difficiles
à analyser pour le solveur.  Une seconde solution consiste à ajouter
des contraintes au problème. Ces contraintes sont exprimées sous la
forme d'équation ou d'inéquation déterminant si une solution donnée
est une solution acceptable. En robotique, des contraintes très
courantes sont les bornes sur les butées articulaires. Il est rare sur
un robot que les axes puissent bouger de manière totalement libre. De
ce fait, il est courant d'ajouter des contraintes inégalités
spécifiant que tel ou tel valeur de joint doit rester dans un
intervalle donné.


En exprimant comment résoudre un problème pratique via la construction
d'une fonction de coût $f$ et de contraintes $g_i > 0$,
\textbf{modélise} le problème afin qu'il soit soluble par optimisation
numérique. Ce procédé n'est pas trivial car la qualité de la
modélisation impacte lourdement à la fois les temps de calcul et la
qualité du résultat final.



\subsection{Modélisation mathématique d'un problème}


Résoudre un problème d'optimisation revient à trouver une solution pour:

\begin{equation}
  \min_{\mathbf{x} \in \mathbb{R}^n} f(x) \text{ sous la contrainte } \mathbf{x} \in \mathbf{X}
\end{equation}

où $f : \mathbb{R}^n \mapsto \mathbb{R}$ est la fonction de coût et
$\mathbf{X} \subset \mathbb{R}^n$ est l'espace des solutions
admissibles. Cet espace est habituellement défini par un ensemble de
contraintes égalités et inégalités:

\begin{equation}
  \mathbf{X} \equiv \left\{ 
  \begin{array}{l l}
    c_i (x) = 0    & \quad i \in \xi \\
    c_j (x) \leq 0 & \quad j \in \nu \\
  \end{array} \right.
\end{equation}

$c_i$, $c_j$ sont respectivement les ensembles de contraintes égalités
et inégalités. $i$ et $j$ des indices identifiant les contraintes.


L'optimisation numérique a pour objectif de développer des stratégies
-- algorithmes -- pouvant déterminer $\mathbf{x} \in \mathbf{X}$
minimisant les valeurs de la fonction $f$.


En absence d'argument fort tel que la convexité de $f$ ainsi que des
contraintes $c_i, i \in \xi \cup \nu$, la solution $\mathbf{x}$
fournie par le solveur peut être un minimum local.


En effet, la plupart des méthodes d'optimisation tentent de trouver un
minimum en raffinant itérativement une solution à partir d'un candidat
initial $\mathbf{x_{\text{init}}} \in \mathbf{X}$. Le solveur, dès
lors, nécessite un critère d'arrêt à ce processus itératif. Ce critère
est donné par les conditions de Karush-Kuhn-Tucker ou conditions KKT.

\begin{mydef}\label{def:chap1_kkt}
Si $\mathbf{x} \in \mathbf{X}$ est un minimum local, alors il existe
$\lambda_i, i \in \xi$ et $\mu_j, j \in \nu$ des constantes non-nulles
appelées multiplicateurs KKT tels que:
%
\begin{description}
\item[\textbf{Critère de stabilité}] \begin{equation}
  \nabla f(x) + \sum_{i \in \xi} \lambda_i c_i(x) + \sum_{j \in \nu} \mu_i c_i(x) = 0
\end{equation}
\item[\textbf{Critère de faisabilité primale}] \begin{equation}
\left\{ 
\begin{array}{l l}
  c_i (x) = 0    & \quad i \in \xi \\
  c_j (x) \leq 0 & \quad j \in \nu \\
\end{array} \right.
\end{equation}
\item[\textbf{Critère de faisabilité duale}] \begin{equation}
\mu_j \geq 0, j \in \nu
\end{equation}
\item[\textbf{Critère de complémentarité}] \begin{equation}
\mu_j c_j(x) = 0, j \in \nu
\end{equation}
\end{description}
\end{mydef}

Il est à noter que la Définition~\ref{def:chap1_kkt} fournit des
conditions suffisantes afin de déterminer si un point est un minimum
local. Sous conditions de régularité, et dans le cas où le problème
est convexe, les conditions KKT sont nécessaires et suffisantes.


\subsection{Zoologie des solveurs}

test


\section[FIXME]{De la dif\-ficulté à passer d'un paradigme uni\-que à une implémentation unifiée}

test

\subsection{Solveurs disponibles}

test

\subsection{Motivation}

test


\section{Architecture logicielle de Roboptim}

test

\section{Scénarii d'utilisation}

test

\subsection[FIXME]{\'Ecriture d'une application robotique complexe: optimiser la trajectoire de marche pour un robot humanoïde}

test

\subsection{Intégration d'un solveur tiers et extensibilité de RobOptim}

test

\section{Discussions}

test

\section{Conclusion}

test
